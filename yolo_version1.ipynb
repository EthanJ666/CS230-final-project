{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]: 100%|██████████| 707/707 [14:38<00:00,  1.24s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Loss: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/5]: 100%|██████████| 707/707 [14:29<00:00,  1.23s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Loss: 0.0283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/5]: 100%|██████████| 707/707 [14:34<00:00,  1.24s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Loss: 0.0225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/5]: 100%|██████████| 707/707 [14:29<00:00,  1.23s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Loss: 0.0190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/5]: 100%|██████████| 707/707 [14:33<00:00,  1.24s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Loss: 0.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/5]: 100%|██████████| 707/707 [14:31<00:00,  1.23s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Loss: 0.0156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/5]: 100%|██████████| 707/707 [14:31<00:00,  1.23s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Loss: 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/5]: 100%|██████████| 707/707 [14:36<00:00,  1.24s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Loss: 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/5]: 100%|██████████| 707/707 [14:35<00:00,  1.24s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Loss: 0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/5]: 100%|██████████| 707/707 [14:29<00:00,  1.23s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Loss: 0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/5]: 100%|██████████| 707/707 [14:24<00:00,  1.22s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/5]: 100%|██████████| 707/707 [14:23<00:00,  1.22s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/5]: 100%|██████████| 707/707 [14:23<00:00,  1.22s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Loss: 0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/5]: 100%|██████████| 707/707 [14:38<00:00,  1.24s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Loss: 0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/5]: 100%|██████████| 707/707 [14:21<00:00,  1.22s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/5]: 100%|██████████| 707/707 [14:23<00:00,  1.22s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Loss: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/5]: 100%|██████████| 707/707 [14:26<00:00,  1.23s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], Loss: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/5]: 100%|██████████| 707/707 [14:21<00:00,  1.22s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18], Loss: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/5]: 100%|██████████| 707/707 [14:22<00:00,  1.22s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19], Loss: 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/5]: 100%|██████████| 707/707 [14:22<00:00,  1.22s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], Loss: 0.0085\n",
      "Finished Training\n",
      "Model saved as yolo_model.pth\n",
      "Starting Testing\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "def create_conv_block(in_channels, out_channels, kernel_size, stride, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.LeakyReLU(0.1),\n",
    "    )\n",
    "\n",
    "class YOLO(nn.Module):\n",
    "    def __init__(self, grid_size):\n",
    "        super(YOLO, self).__init__()\n",
    "        self.grid_size = grid_size\n",
    "        \n",
    "        self.conv1 = create_conv_block(3, 16, 3, 1, 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = create_conv_block(16, 32, 3, 1, 1)\n",
    "        self.conv3 = create_conv_block(32, 64, 3, 1, 1)\n",
    "        self.conv4 = create_conv_block(64, 128, 3, 1, 1)\n",
    "        self.conv5 = create_conv_block(128, 256, 3, 1, 1)\n",
    "        self.fc1 = nn.Linear(256 * (640 // 32) * (640 // 32), 1024)\n",
    "        self.fc2 = nn.Linear(1024, grid_size * grid_size * (5 + 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = self.pool(self.conv3(x))\n",
    "        x = self.pool(self.conv4(x))\n",
    "        x = self.pool(self.conv5(x))\n",
    "        x = x.view(-1, 256 * (640 // 32) * (640 // 32))\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class CustomYOLODataset(Dataset):\n",
    "    def __init__(self, image_folder, label_folder, grid_size, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.label_folder = label_folder\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(image_folder) if f.endswith('.jpg')]\n",
    "        self.grid_size=grid_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_folder, self.image_files[idx])\n",
    "        label_path = os.path.join(self.label_folder, self.image_files[idx].replace('.jpg', '.txt'))\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        #double check this transformation\n",
    "        label = torch.zeros((grid_size, grid_size, 6))\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    class_id, x, y, w, h = map(float, line.split())\n",
    "                    grid_x = math.floor(x * self.grid_size)\n",
    "                    grid_y = math.floor(y * self.grid_size)\n",
    "                    x_offset = (x * self.grid_size) - grid_x\n",
    "                    y_offset = (y * self.grid_size) - grid_y\n",
    "                    label[grid_y, grid_x, :] = torch.tensor([x_offset, y_offset, w, h, 1, class_id])\n",
    "        else:\n",
    "            raise Exception(f'{label_path} does not exist')\n",
    "\n",
    "        return image, label.view(-1)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((640, 640)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "grid_size = 7\n",
    "num_epochs = 20\n",
    "batch_size = 4\n",
    "\n",
    "train_folder = '/Users/devinma/Desktop/Stanford/CS230/DroneSegment.v1i.yolov5pytorch/train'\n",
    "train_folder = '/Users/devinma/Desktop/Stanford/CS230/DroneSegment.v1i.yolov5pytorch/test'\n",
    "output_folder = '/Users/devinma/Desktop/Stanford/CS230/DroneSegment.v1i.yolov5pytorch/yolo_v1_output_images'\n",
    "weight_output_folder = '/Users/devinma/Desktop/Stanford/CS230/DroneSegment.v1i.yolov5pytorch/yolo_v1_weights'\n",
    "\n",
    "dataset = CustomYOLODataset(image_folder=train_folder+'/images', label_folder=train_folder+'/labels', grid_size=grid_size, transform=transform)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "yolo = YOLO(grid_size=grid_size)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "yolo = yolo.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(yolo.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, data in enumerate(tqdm(train_loader, desc=f\"Epoch [{epoch + 1}/{num_epochs}]\", unit=\"batch\")):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = yolo(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}], Loss: {running_loss / len(train_loader)}')\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(yolo.state_dict(), weight_output_folder + '/yolo_model.pth')\n",
    "print('Model saved')\n",
    "\n",
    "print('Starting Testing')\n",
    "yolo.eval()\n",
    "test_dataset = CustomYOLODataset(image_folder=train_folder+'/images', label_folder=train_folder+'/labels', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels, img_path = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = yolo(inputs)\n",
    "        predictions = torch.sigmoid(outputs).view(grid_size, grid_size, 6).cpu().numpy()\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend((predictions[..., 0] > 0.5).astype(int))\n",
    "\n",
    "        # Draw boxes on the test images, double check this\n",
    "        original_image = Image.open(img_path[0]).convert('RGB')\n",
    "        draw = ImageDraw.Draw(original_image)\n",
    "\n",
    "        for row in range(grid_size):\n",
    "            for col in range(grid_size):\n",
    "                if predictions[row, col, 4] > 0.5 and predictions[row, col, 5] < 0.5:  # If confidence score is high and classified as 0\n",
    "                    x_offset, y_offset, w, h = predictions[row, col, 0:4]\n",
    "                    x_center = (col + x_offset) / grid_size * 640\n",
    "                    y_center = (row + y_offset) / grid_size * 640\n",
    "                    box_w = w * 640\n",
    "                    box_h = h * 640\n",
    "                    x1 = int(x_center - box_w / 2)\n",
    "                    y1 = int(y_center - box_h / 2)\n",
    "                    x2 = int(x_center + box_w / 2)\n",
    "                    y2 = int(y_center + box_h / 2)\n",
    "                    draw.rectangle([x1, y1, x2, y2], outline='red', width=3)\n",
    "        output_path = os.path.join(output_folder, os.path.basename(img_path[0]))\n",
    "        original_image.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bk/mwh2cx_n5s50p4_xm6vspbhr0000gn/T/ipykernel_73464/2433984317.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Calculate F1 score, precision, and recall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_true_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "#fix bugs to get precision, recall, f1\n",
    "y_true = np.concatenate(y_true).flatten()\n",
    "y_pred = np.concatenate(y_pred).flatten()\n",
    "y_true_binary = (y_true > 0.5).astype(int)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "f1 = f1_score(y_true_binary, y_pred_binary)\n",
    "precision = precision_score(y_true_binary, y_pred_binary)\n",
    "recall = recall_score(y_true_binary, y_pred_binary)\n",
    "\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
